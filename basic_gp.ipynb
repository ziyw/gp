{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of Mon 12th of Oct running on devel branch of GPy 0.8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GPy.plotting.change_plotting_library('plotly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian process regression tutorial\n",
    "\n",
    "### Nicolas Durrande 2013\n",
    "#### with edits by James Hensman and Neil D. Lawrence\n",
    "\n",
    "We will see in this tutorial the basics for building a 1 dimensional and a 2 dimensional Gaussian process regression model, also known as a kriging model.\n",
    "\n",
    "We first import the libraries we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-dimensional model\n",
    "\n",
    "For this toy example, we assume we have the following inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.random.uniform(-3.,3.,(20,1))\n",
    "Y = np.sin(X) + np.random.randn(20,1)*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the observations Y include some noise.\n",
    "\n",
    "The first step is to define the covariance kernel we want to use for the model. We choose here a kernel based on Gaussian kernel (i.e. rbf or square exponential):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter input_dim stands for the dimension of the input space. The parameters `variance` and `lengthscale` are optional, and default to 1. Many other kernels are implemented, type `GPy.kern.<tab>` to see a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#type GPy.kern.<tab> here:\n",
    "GPy.kern.BasisFuncKernel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs required for building the model are the observations and the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = GPy.models.GPRegression(X,Y,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, some observation noise is added to the model. The functions `display` and `plot` give an insight of the model we have just built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 22.9561988543<br>\n",
       "<b>Number of Parameters</b>: 3<br>\n",
       "<b>Number of Optimization Parameters</b>: 3<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>  1.0</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right>  1.0</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>  1.0</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x118661890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name : GP regression\n",
      "Objective : 22.9561988543\n",
      "Number of Parameters : 3\n",
      "Number of Optimization Parameters : 3\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mrbf.variance           \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale        \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "(array([[ 0.38162367],\n",
      "       [-0.41917343],\n",
      "       [ 0.82714198],\n",
      "       [-0.7027065 ],\n",
      "       [-0.72142487],\n",
      "       [ 0.66968864],\n",
      "       [-0.86812438],\n",
      "       [ 0.55026333],\n",
      "       [-0.50776437],\n",
      "       [ 0.40743832],\n",
      "       [-0.88631099],\n",
      "       [-0.45626934],\n",
      "       [ 0.83026154],\n",
      "       [ 0.82113005],\n",
      "       [-0.25109596],\n",
      "       [ 0.50466889],\n",
      "       [ 0.81027829],\n",
      "       [ 0.26670505],\n",
      "       [-0.52768102],\n",
      "       [-0.59771467]]), array([[ 1.33076625],\n",
      "       [ 1.36346383],\n",
      "       [ 1.16954408],\n",
      "       [ 1.18414941],\n",
      "       [ 1.21045104],\n",
      "       [ 1.25808161],\n",
      "       [ 1.14240086],\n",
      "       [ 1.19531629],\n",
      "       [ 1.22303367],\n",
      "       [ 1.30453395],\n",
      "       [ 1.14726452],\n",
      "       [ 1.3324882 ],\n",
      "       [ 1.16137428],\n",
      "       [ 1.17751418],\n",
      "       [ 1.23527364],\n",
      "       [ 1.2238983 ],\n",
      "       [ 1.13982221],\n",
      "       [ 1.30714032],\n",
      "       [ 1.27967307],\n",
      "       [ 1.23590111]]))\n"
     ]
    }
   ],
   "source": [
    "print m\n",
    "Xp = np.random.uniform(-3.,3.,(20,1))\n",
    "print m.predict(Xp)\n",
    "\n",
    "\n",
    "\n",
    "# fig = m.plot()\n",
    "# GPy.plotting.show(fig, filename='basic_gp_regression_notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows our GP regression model before optimization of the parameters. The shaded region corresponds to ~95% confidence intervals (ie +/- 2 standard deviation).\n",
    "\n",
    "The default values of the kernel parameters may not be optimal for the current data (for example, the confidence intervals seems too wide on the previous figure). A common approach is to find the values of the parameters that maximize the likelihood of the data. It as easy as calling `m.optimize` in GPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to perform some restarts to try to improve the result of the optimization, we can use the `optimize_restarts` function. This selects random (drawn from $N(0,1)$) initializations for the parameter values, optimizes each, and sets the model to the best solution found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.optimize_restarts(num_restarts = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, the objective function (usually!) has only one local minima, and each of the found solutions are the same. \n",
    "\n",
    "Once again, we can use `print(m)` and `m.plot()` to look at the resulting model resulting model. This time, the paraemters values have been optimized agains the log likelihood (aka the log marginal likelihood): the fit shoul dbe much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(m)\n",
    "fig = m.plot()\n",
    "GPy.plotting.show(fig, filename='basic_gp_regression_notebook_optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New plotting of GPy 0.9 and later\n",
    "The new plotting allows you to plot the density of a GP object more fine grained by plotting more percentiles of the distribution color coded by their opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(m)\n",
    "fig = m.plot(plot_density=True)\n",
    "GPy.plotting.show(fig, filename='basic_gp_regression_density_notebook_optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-dimensional example\n",
    "\n",
    "Here is a 2 dimensional example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample inputs and outputs\n",
    "X = np.random.uniform(-3.,3.,(50,2))\n",
    "Y = np.sin(X[:,0:1]) * np.sin(X[:,1:2])+np.random.randn(50,1)*0.05\n",
    "\n",
    "# define kernel\n",
    "ker = GPy.kern.Matern52(2,ARD=True) + GPy.kern.White(2)\n",
    "\n",
    "# create simple GP model\n",
    "m = GPy.models.GPRegression(X,Y,ker)\n",
    "\n",
    "# optimize and plot\n",
    "m.optimize(messages=True,max_f_eval = 1000)\n",
    "fig = m.plot()\n",
    "display(GPy.plotting.show(fig, filename='basic_gp_regression_notebook_2d'))\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flag `ARD=True` in the definition of the `Matern` kernel specifies that we want one lengthscale parameter per dimension (ie the GP is not isotropic). Note that for 2-d plotting, only the mean is shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting slices\n",
    "To see the uncertaintly associated with the above predictions, we can plot slices through the surface. this is done by passing the optional `fixed_inputs` argument to the plot function. `fixed_inputs` is a list of tuples containing which of the inputs to fix, and to which value.\n",
    "\n",
    "To get horixontal slices of the above GP, we'll fix second (index 1) input to -1, 0, and 1.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slices = [-1, 0, 1.5]\n",
    "figure = GPy.plotting.plotting_library().figure(3, 1, \n",
    "                        shared_xaxes=True,\n",
    "                        subplot_titles=('slice at -1', \n",
    "                                        'slice at 0', \n",
    "                                        'slice at 1.5', \n",
    "                                        )\n",
    "                            )\n",
    "for i, y in zip(range(3), slices):\n",
    "    canvas = m.plot(figure=figure, fixed_inputs=[(1,y)], row=(i+1), plot_data=False)\n",
    "GPy.plotting.show(canvas, filename='basic_gp_regression_notebook_slicing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    " * we've also passed the optional `ax` argument, to mnake the GP plot on a particular subplot\n",
    " * the data look strange here: we're seeing slices of the GP, but all the data are displayed, even though they might not be close to the current slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get vertical slices, we simply fixed the other input. We'll turn the display of data off also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slices = [-1, 0, 1.5]\n",
    "figure = GPy.plotting.plotting_library().figure(3, 1, \n",
    "                        shared_xaxes=True,\n",
    "                        subplot_titles=('slice at -1', \n",
    "                                        'slice at 0', \n",
    "                                        'slice at 1.5', \n",
    "                                        )\n",
    "                            )\n",
    "for i, y in zip(range(3), slices):\n",
    "    canvas = m.plot(figure=figure, fixed_inputs=[(0,y)], row=(i+1), plot_data=False)\n",
    "GPy.plotting.show(canvas, filename='basic_gp_regression_notebook_slicing_vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a host of other plotting options in the `m.plot` docstring. `Type m.plot?<enter>` to see. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
